{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AM 207**: Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verena Kaynig-Fittkau and Pavlos Protopapas  <br>\n",
    "**Due: 11.59 P.M. Thursday April 14th, 2016**\n",
    "\n",
    "### Note: This homework is only for one week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "+ Upload your answers in an ipython notebook to Canvas.\n",
    "\n",
    "+ We will provide you imports for your ipython notebook. Please do not import additional libraries.\n",
    "\n",
    "+ Your individual submissions should use the following filenames: AM207_YOURNAME_HW5.ipynb\n",
    "\n",
    "+ Your code should be in code cells as part of your ipython notebook. Do not use a different language (or format). \n",
    "\n",
    "+ **Do not just send your code. The homework solutions should be in a report style. Be sure to add comments to your code as well as markdown cells where you describe your approach and discuss your results. **\n",
    "\n",
    "+ Please submit your notebook in an executed status, so that we can see all the results you computed. However, we will still run your code and all cells should reproduce the output when executed. \n",
    "\n",
    "+ If you have multiple files (e.g. you've added code files or images) create a tarball for all files in a single file and name it: AM207_YOURNAME_HW5.tar.gz or AM207_YOURNAME_HW5.zip\n",
    "\n",
    "\n",
    "### Have Fun!\n",
    "_ _ _ _ _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import scipy.stats \n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: HMM... I Think Your Text Got Corrupted!\n",
    "\n",
    "In this problem you should use a Hidden Markov Model to correct typos in a text without using a dictionary. Your data is in two different text files:\n",
    "\n",
    "* `Shakespeare_correct.txt` contains the words of some sonnets from Shakespeare\n",
    "* `Shakespeare_typos.txt` contains the same text, but now some of the characters are corrupted\n",
    "\n",
    "For convenience both text files only contain lower case letters a-z and spaces. \n",
    "\n",
    "First build a first order HMM:\n",
    "* What are the hidden states and what are the observed states?\n",
    "* What should you do to generate your HMM probability matrices?\n",
    "* For some of the HMM parameters, you won't have enough training data to get representative probabilities.  For example, some of your probabilites might be 0. You should address this problem by adding a small pseudocount, similar to the motif finding problem from a previous assignment. \n",
    "* Implement the Viterbi algorithm and run it on a test portion that contains errors. Show that your Viterbi implementation can improve text of length 100, 500, 1000, and 2000. Note: To do this correctly you would have to withhold the part of the text that you use for testing when you estimate the parameters for you HMM. For the sake of this homework it is ok though to report training error instead of test error. Just be aware that the correction rate you are reporting most likely is a very optimistic estimate. \n",
    "* What correction rate do you get?\n",
    "\n",
    "**Important**: Wikipedia has a nice article on [Viterbi](https://en.wikipedia.org/wiki/Viterbi_algorithm). **Please do not use the python implementation from this article!** (The lecture notebook also has the version from Wikipedia). Using dictionaries for Viterbi is really not intuitive and using numpy is typically faster. The article has very nice pseudo code that should enable you to easily program Viterbi by yourself. Please also refrain for this problem from using any other third party implementations. \n",
    "\n",
    "Now for a second order HMM:\n",
    "By using a second order HMM, you should be able to get a better correction rate. \n",
    "* Give an intuitive explanation why a second order HMM should give better results.\n",
    "* Implement your second order text correction. Hint: If you think a bit about the model you won't even have to change your Viterbi implementation. \n",
    "* Compare your correction rates against the first order model for text length of 100 and 500, (you can do 1000 as well if your computer is fast enough). \n",
    "* How well would your implementation scale to HMMs of even higher order? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Problem 2: Final Project Review\n",
    "    \n",
    "You will be contacted shortly by a TF to meet and discuss your final project proposal. Be sure to take advantage of this feedback option. Review meetings should be scheduled within the week from April 11-15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of correct letter is, 60208\n",
      "length of typo letter is 60208\n",
      "1st order HMM starts ...\n",
      "\n",
      "(100, 27)\n",
      "correction rate = 0.6 \n",
      " typo list = fron fbirest crebtuses we eesjsf iocrease uhat therfbz bebuuys rose night never eie buu as uie siper \n",
      " corrected list = fron fairest breatuses we desise increase that thereay beautys rore might mever die but as the siper \n",
      " true list= from fairest creatures we desire increase that thereby beautys rose might never die but as the riper\n",
      "\n",
      "2nd order HMM starts ...\n",
      "['fr', 'ro', 'on', 'n ', ' f', 'fb', 'bi', 'ir', 're', 'es', 'st', 't ', ' c', 'cr', 're', 'eb', 'bt', 'tu', 'us', 'se', 'es', 's ', ' w', 'we', 'e ', ' e', 'ee', 'es', 'sj', 'js', 'sf', 'f ', ' i', 'io', 'oc', 'cr', 're', 'ea', 'as', 'se', 'e ', ' u', 'uh', 'ha', 'at', 't ', ' t', 'th', 'he', 'er', 'rf', 'fb', 'bz', 'z ', ' b', 'be', 'eb', 'bu', 'uu', 'uy', 'ys', 's ', ' r', 'ro', 'os', 'se', 'e ', ' n', 'ni', 'ig', 'gh', 'ht', 't ', ' n', 'ne', 'ev', 've', 'er', 'r ', ' e', 'ei', 'ie', 'e ', ' b', 'bu', 'uu', 'u ', ' a', 'as', 's ', ' u', 'ui', 'ie', 'e ', ' s', 'si', 'ip', 'pe', 'er', 'r ']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 180 is out of bounds for axis 1 with size 27",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-be219df5c2a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m#emission_states = ' abcdefghijklmnopqrstuvwxyz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mstart_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memission_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mbest_log_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_2nd_order\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_2nd_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memission_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT_2nd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'full hidden states ='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[0mbest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-be219df5c2a9>\u001b[0m in \u001b[0;36mviterbi\u001b[1;34m(obs, hidden_states, emission_states, start_p, trans_p, emit_p)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     '''\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_p\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memit_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memission_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     '''\n\u001b[0;32m    170\u001b[0m     \u001b[0mincr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_states\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memission_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 180 is out of bounds for axis 1 with size 27"
     ]
    }
   ],
   "source": [
    "#load in word sequences\n",
    "with open('Shakespeare_correct.txt', 'r') as myfile:\n",
    "    data = myfile.read() \n",
    "correct_l_len = len(data)\n",
    "print 'length of correct letter is,', correct_l_len\n",
    "correct_letters = data\n",
    "#correct_words = data.split(' ')\n",
    "\n",
    "with open('Shakespeare_typos.txt', 'r') as myfile:\n",
    "    data=myfile.read()  \n",
    "typo_len = len(data)\n",
    "typo_letters = data\n",
    "print 'length of typo letter is', typo_len\n",
    "#typo_words = data.split(' ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#function to calculate transition matrix of letters and spaces\n",
    "def calc_1st_trans_prob(s1 = correct_letters):\n",
    "    #initialize \n",
    "    ref_string = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    T = np.zeros((27,27),dtype = 'float')\n",
    "    for i in range(1,len(s1)):\n",
    "        row_zkm1 = ref_string.index(s1[i-1])\n",
    "        col_zk = ref_string.index(s1[i])\n",
    "        T[row_zkm1,col_zk] +=1\n",
    "        \n",
    "    #normalize and add pseudocount\n",
    "    pseudocount = 0.1\n",
    "    T += pseudocount\n",
    "    \n",
    "    for i in range(T.shape[0]):\n",
    "        T[i,:] = T[i,:] / np.sum(T[i,:])\n",
    "    \n",
    "    return T\n",
    "\n",
    "#calculate 2nd order transition matrix of letters and spaces\n",
    "def calc_2nd_trans_prob(s1 = correct_letters):\n",
    "    #initialize \n",
    "    ref_string = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    T = np.zeros((27**2,27**2),dtype = 'float')\n",
    "    for i in range(2,len(s1)):\n",
    "        row_zkm1_zkm2 = ref_string.index(s1[i-2]) * 27 + ref_string.index(s1[i-1])\n",
    "        col_zk_zkm1 = ref_string.index(s1[i-1])*27 + ref_string.index(s1[i])\n",
    "        T[row_zkm1_zkm2,col_zk_zkm1] +=1\n",
    "        \n",
    "    #normalize and add pseudocount\n",
    "    pseudocount = 0.1\n",
    "    T += pseudocount\n",
    "    \n",
    "    for i in range(T.shape[0]):\n",
    "        T[i,:] = T[i,:] / np.sum(T[i,:])\n",
    "    \n",
    "    return T\n",
    "\n",
    "def generate_2nd_HMM_states():\n",
    "    states = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    hidden_states = [None] * (27**2)\n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(states)):\n",
    "            hidden_states[i*27 + j] = states[i] + states[j]\n",
    "    \n",
    "\n",
    "    return hidden_states\n",
    "\n",
    "#function to generate second order observation inputs\n",
    "def generate_2nd_HMM_obs(obs):\n",
    "    obs_2nd_order = [None] * (len(obs)-1)\n",
    "    for i in range(len(obs)-1):\n",
    "        obs_2nd_order[i] = obs[i] + obs[i+1]\n",
    "\n",
    "    return obs_2nd_order\n",
    "\n",
    "#function to calculate emission probability matrix of letters and spaces\n",
    "def calc_emission_prob(s1 = correct_letters, s2 = typo_letters):\n",
    "    #initialize \n",
    "    ref_string = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    E = np.zeros((27,27),dtype = 'float')\n",
    "    for i in range(0,len(s1)):\n",
    "        row_zk = ref_string.index(s1[i])\n",
    "        col_xk = ref_string.index(s2[i])\n",
    "        E[row_zk,col_xk] +=1\n",
    "        \n",
    "    #normalize and add pseudocount\n",
    "    pseudocount = 0.1\n",
    "    E += pseudocount\n",
    "    \n",
    "    for i in range(E.shape[0]):\n",
    "        E[i,:] = E[i,:] / np.sum(E[i,:])\n",
    "    \n",
    "    return E\n",
    "\n",
    "\n",
    "#compute the 1st order transition matrix based on correct words\n",
    "'''\n",
    "T = np.zeros((num_correct_words,num_correct_words),dtype = 'float')\n",
    "for i in range(1,len_sequence):\n",
    "    row_zkm1 = sorted_correct_words.index(correct_words[i-1])\n",
    "    col_zk   = sorted_correct_words.index(correct_words[i])\n",
    "    T[row_zkm1,col_zk] += 1\n",
    "\n",
    "#normalize and add pseudocount\n",
    "for i in range(T.shape[0]):\n",
    "    temp_sum = np.sum(T[i,:])\n",
    "    if temp_sum > 0:\n",
    "        T[i,:] = T[i,:]/temp_sum\n",
    "    else:\n",
    "        T[i,:] = 1.0/T.shape[0]\n",
    "        #print 'here', 1/T.shape[0]\n",
    "'''\n",
    "#print T\n",
    "\n",
    "# generate P(x|z) on spot!!\n",
    "#compute the emission matrix \n",
    "#E = np.zeros(dtype='float')            \n",
    "\n",
    "#function that calculates emission probability\n",
    "#x: observed \n",
    "#z: hidden states\n",
    "def calc_emit_prob(x,states):\n",
    "    l = 0.01\n",
    "    emit_prob = np.zeros(len(states),dtype ='float')\n",
    "    for (indz,z) in enumerate(states):\n",
    "        if len(x) == len(z):\n",
    "            dist = len(x) - [s1 == s2 for (s1, s2) in zip(x, z)].count(True)\n",
    "            emit_prob[indz] = l ** dist / scipy.misc.factorial(l)\n",
    "        else:\n",
    "            emit_prob[indz] = 0\n",
    "    return emit_prob\n",
    "\n",
    "#calculate correction rate\n",
    "def calc_correction_rate(ref_list,typo_list,corrected_list):\n",
    "    \n",
    "    typo_match_rate = calc_match_rate(ref_list,typo_list)\n",
    "    corr_match_rate = calc_match_rate(ref_list,corrected_list)\n",
    "    \n",
    "    return (corr_match_rate - typo_match_rate) / (1 - typo_match_rate)\n",
    "\n",
    "#calculate match rate\n",
    "def calc_match_rate(list_a,list_b):\n",
    "    num_words = len(list_a)\n",
    "    num_correct = 0;\n",
    "    for i in range(num_words):\n",
    "        if list_a[i] == list_b[i]:\n",
    "            num_correct += 1\n",
    "\n",
    "    return (num_correct + 0.0) / (num_words) +0.0\n",
    "    \n",
    "#numpy viterbi implementation:\n",
    "def viterbi(obs, hidden_states,emission_states, start_p, trans_p, emit_p):\n",
    "    \n",
    "    #initialize:\n",
    "    len_obs = len(obs)       #length of observation test string \n",
    "    num_states = len(hidden_states) #number of states, here 27 or 27**2\n",
    "    V = np.zeros((len_obs,num_states),dtype = 'float') #log probabilities\n",
    "    path = np.zeros((len_obs,num_states),dtype = 'int') -1\n",
    "    \n",
    "    #initialize base case\n",
    "    '''\n",
    "    for (indz,z) in enumerate(states):\n",
    "        print indz, z\n",
    "        print np.log(start_p[indz])\n",
    "        print np.log(calc_emit_prob(obs[0],z))\n",
    "        V[0,indz] = np.log(start_p[indz]) + np.log(calc_emit_prob(obs[0],z))\n",
    "        path[0,indz] = indz\n",
    "    '''\n",
    "    V[0,:] = np.log(start_p) + np.log(emit_p[:,emission_states.index(obs[0])].transpose())\n",
    "    '''\n",
    "    incr = num_states / len(emission_states)\n",
    "    for i in range(len(emission_states)):\n",
    "        V[0,(i*incr):((i+1)*incr)] += np.log(emit_p[i,emission_states.index(obs[0])])\n",
    "    '''\n",
    "    #path[0,:] = np.arange(0,num_states)\n",
    "    \n",
    "    #print 'starting...', np.log(calc_emit_prob(obs[0],states))\n",
    "    \n",
    "    print V.shape\n",
    "    #assert(0)\n",
    "    \n",
    "    #run viterbi for t>0 \n",
    "    for t in range(1,len(obs)):\n",
    "        #print t\n",
    "        #log_emit_prob = np.log(calc_emit_prob(obs[t],states))\n",
    "        log_emit_prob = np.log(emit_p[:,emission_states.index(obs[t])].transpose())\n",
    "        #print 't =' ,t ,', log_emit_prob=' ,log_emit_prob\n",
    "        \n",
    "        for (indz, z) in enumerate(emission_states):\n",
    "\n",
    "            #log_prob_vec = V[t-1,:] + np.log(trans_p[:,indz].transpose()) + np.log(calc_emit_prob(obs[t],states))\n",
    "            log_prob_vec = V[t-1,:] + np.log(trans_p[:,indz].transpose()) + log_emit_prob[indz]\n",
    "            V[t,indz] = np.max(log_prob_vec)\n",
    "            path[t-1,indz] = np.argmax(log_prob_vec)\n",
    "            \n",
    "            #print 'z= ', z, ',transition prob =', trans_p[indz,:].transpose(), \\\n",
    "            #      ',emission prob = ', np.exp(log_emit_prob[indz]), ',path=', path, \\\n",
    "            #      ',V[t,indz] =', V[t,indz]\n",
    "    \n",
    "    #find best solution based on IC\n",
    "    #print 'writing solution...\\n'\n",
    "    best_ind = np.argmax(V[t,:])\n",
    "    path[t,best_ind] = best_ind\n",
    "    #print 'best indices is: ', best_ind\n",
    "    #print 'final path =', path\n",
    "    best_log_prob = V[t,best_ind]\n",
    "    #best_path_ind = path[:,best_ind]\n",
    "    \n",
    "    #best_path = [states[best_ind]]\n",
    "    ##best_path = hidden_states[best_ind]\n",
    "    best_path = emission_states[best_ind]\n",
    "    \n",
    "    col_ind = best_ind\n",
    "    for i in range(len(obs)-2,-1,-1):\n",
    "        col_ind = path[i,col_ind]\n",
    "        #best_path.append(states[col_ind])\n",
    "        ##best_path += hidden_states[col_ind]\n",
    "        best_path += emission_states[col_ind]\n",
    "    \n",
    "    #best_path = best_path[-1::-len(hidden_states[0])]\n",
    "    best_path = best_path[::-1]\n",
    "    #print best_path\n",
    "    #print 'V=', V\n",
    "    #print best_log_prob\n",
    "    #print 'best_path =', best_path\n",
    "    #print 'obs =', obs\n",
    "    return best_log_prob, best_path\n",
    "\n",
    "#testing\n",
    "#print a_vec.index('a')\n",
    "\n",
    "\n",
    "#driver script\n",
    "if __name__ == '__main__':\n",
    "    print '1st order HMM starts ...\\n'\n",
    "    \n",
    "    #generate 1st order transition matrices\n",
    "    T_1st = calc_1st_trans_prob()\n",
    "    #print T_1st\n",
    "    \n",
    "    #generate 2nd order transition matrices\n",
    "    T_2nd = calc_2nd_trans_prob()\n",
    "    \n",
    "    E = calc_emission_prob()\n",
    "    #print E\n",
    "    \n",
    "    \n",
    "    #1st order HMM\n",
    "    \n",
    "    hidden_1st_states = list(' abcdefghijklmnopqrstuvwxyz')\n",
    "    emission_states = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    start_p = np.ones(len(emission_states),dtype = 'float')\n",
    "    best_log_prob, best_path = viterbi(typo_letters[0:100],hidden_1st_states,emission_states,start_p,T_1st,E)\n",
    "    correct_rate = calc_correction_rate(correct_letters[0:100],typo_letters[0:100],best_path)\n",
    "    print 'correction rate =', correct_rate, '\\n typo list =', typo_letters[0:100], '\\n corrected list =', \\\n",
    "          best_path, '\\n true list=', correct_letters[0:100]\n",
    "       \n",
    "    #2nd order HMM\n",
    "    #print generate_2nd_HMM_states()\n",
    "    \n",
    "    print '\\n2nd order HMM starts ...'\n",
    "    hidden_2nd_states = generate_2nd_HMM_states()\n",
    "    emission_states = generate_2nd_HMM_states()\n",
    "    obs_2nd_order = generate_2nd_HMM_obs(typo_letters[0:101])\n",
    "    print obs_2nd_order\n",
    "    #emission_states = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    start_p = np.ones(len(emission_states)**2,dtype = 'float')\n",
    "    best_log_prob, best_path = viterbi(obs_2nd_order,hidden_2nd_states,emission_states,start_p,T_2nd,E)\n",
    "    print 'full hidden states =', best_path\n",
    "    best_path = best_path[0::2]\n",
    "    correct_rate = calc_correction_rate(correct_letters[0:100],typo_letters[0:100],best_path)\n",
    "    print 'correction rate =', correct_rate, '\\n typo list =', typo_letters[0:100], '\\n corrected list =', \\\n",
    "          best_path, '\\n true list=', correct_letters[0:100]\n",
    "    \n",
    "    \n",
    "    #start_p = np.ones(len(sorted_correct_words),dtype = 'float')\n",
    "    #print 'typo words are, ', typo_words[0:10]\n",
    "    #print 'states are', sorted_correct_words\n",
    "    #best_log_prob, best_path = viterbi(typo_words[100:200],sorted_correct_words,start_p,T)\n",
    "    #correct_rate = calc_correction_rate(best_path,correct_words[100:200])\n",
    "    #print 'correction rate =', correct_rate, '\\n corrected list =', \\\n",
    "    #      best_path, '\\n original list=', correct_words[100:200]\n",
    "\n",
    "\n",
    "\n",
    "#testing code\n",
    "'''\n",
    "a = [\"asd\",\"def\",\"ase\",\"dfg\",\"asd\",\"def\",\"dfg\"]\n",
    "a = list(set(a))\n",
    "b = sorted(a)\n",
    "print a, '\\n', b\n",
    "\n",
    "import operator\n",
    "print dist , dist2\n",
    "\n",
    "print 'emission prob', calc_emit_prob('abc',['abc','asd'])\n",
    "print 'emission prob', calc_emit_prob('abc',['abc','asdc'])\n",
    "print 'emission prob', calc_emit_prob('abc',['acb','asd'])\n",
    "print 'emission prob', calc_emit_prob('abc',['abe','asd'])\n",
    "print b.index(\"def\")\n",
    "\n",
    "v= []\n",
    "for i in range(10):\n",
    "    v.append('a')\n",
    "print v\n",
    "\n",
    "for (inda,suba) in enumerate(a):\n",
    "    print inda, suba\n",
    "\n",
    "\n",
    "a_vec = ['asd','sda','sda']\n",
    "b_vec = ['asd','ccc','sdc']\n",
    "\n",
    "\n",
    "print calc_correction_rate(a_vec,b_vec)\n",
    "'''\n",
    "\n",
    "#print num_correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
