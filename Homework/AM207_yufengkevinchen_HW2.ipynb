{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AM 207**: Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verena Kaynig-Fittkau and Pavlos Protopapas  <br>\n",
    "**Due: 11.59 P.M. Thursday March 3rd, 2015**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "+ Upload your answers in an ipython notebook to Canvas.\n",
    "\n",
    "+ We will provide you imports for your ipython notebook. Please do not import additional libraries.\n",
    "\n",
    "+ Your individual submissions should use the following filenames: AM207_YOURNAME_HW2.ipynb\n",
    "\n",
    "+ Your code should be in code cells as part of your ipython notebook. Do not use a different language (or format). \n",
    "\n",
    "+ **Do not just send your code. The homework solutions should be in a report style. Be sure to add comments to your code as well as markdown cells where you describe your approach and discuss your results. **\n",
    "\n",
    "+ Please submit your notebook in an executed status, so that we can see all the results you computed. However, we will still run your code and all cells should reproduce the output when executed. \n",
    "\n",
    "+ If you have multiple files (e.g. you've added code files or images) create a tarball for all files in a single file and name it: AM207_YOURNAME_HW2.tar.gz or AM207_YOURNAME_HW2.zip\n",
    "\n",
    "\n",
    "### Have Fun!\n",
    "_ _ _ _ _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import scipy.stats \n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Geweke Convergence Test\n",
    "\n",
    "In the lecture we have seen the Geweke test as one option to test for convergence of our metropolis hastings chain. Describe in your own words how the Geweke test works and its limitations. \n",
    "\n",
    "We provide you with the following code for the Geweke test. Write comments for the marked lines and any lines you think would be good to explain in addition. \n",
    "\n",
    "Write a short explanation of what the `rhot` function does and why it is necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Geweke test compares the z-score (mean over scaled variance) of segments of a sampled distribution to determine if the samples reach the steady state of the Markov Chain. Intuitively, the earlier part of the samples need to be similar to the later part to demonstrate convergence. Nominally we take $\\pm2$ standard deviation as our metric for convergence. The limitation of this method is that it cannot provide a proof for convergence. In addition, it is sensitive to the spectral distribution of the samples. \n",
    "\n",
    "Please refer to the comments below. \n",
    "\n",
    "The rhot function computes the correlation between symmetric parts of the input data. Ideally we want to input data to be independent. However, we know MCMC gives correlated sampels. The rhot function gives the correction factor for the correlated samples. If the input samples are truely independent, then the loop involving rhot returns 1. Mathematically, the z-score is given by: \n",
    "\n",
    "$z = \\frac{\\bar{\\theta_a}-\\bar{\\theta_b}}{\\sqrt{\\frac{S(\\theta_a)}{m}+\\frac{S(\\theta_b)}{n}}}$.\n",
    "\n",
    "Here $S()$ is the scale variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return the correlation coefficient between symmetric parts of input data\n",
    "# note x[0:(n-t)] , x[t:n] have equal length\n",
    "def rhot(x, t):\n",
    "    n = len(x)\n",
    "    return np.corrcoef(x[0:(n-t)], x[t:n])[0,1]\n",
    "\n",
    "# \n",
    "def Geweke(trace, intervals, length):\n",
    "    nsl=length\n",
    "    #step size to divide data into number of intervals(range from 10% to 100%)\n",
    "    jump = int(0.9*len(trace)/(2*intervals))\n",
    "    #start index of the 1st interval\n",
    "    first = 0.1*len(trace)\n",
    "    \n",
    "    z =np.empty(intervals)\n",
    "    #loop: compute the z-score for each interval\n",
    "    for k in np.arange(0, intervals):\n",
    "        # compute the start index of segment a\n",
    "        baga = np.int(first+k*jump)\n",
    "        # compute the start index of segment b\n",
    "        bagb = len(trace)/2 + k*jump\n",
    "        \n",
    "        # obtain local segment a and b from the full data 'trace'\n",
    "        sub_trace_a = trace[baga:baga+nsl]\n",
    "        sub_trace_b = trace[bagb:bagb+nsl]\n",
    "        \n",
    "        # calculate the mean of segment a and b\n",
    "        theta_a = np.mean(sub_trace_a)\n",
    "        theta_b = np.mean(sub_trace_b)\n",
    "        rho_a, rho_b = 1.0, 1.0\n",
    "        # loop: loop through the pivoting indices for segment a and b\n",
    "        for i in xrange(int(0.1*nsl)):\n",
    "            # sum correlation coefficient of each symmetric parts of segment a and b\n",
    "            rho_a += 2*rhot(sub_trace_a, i+1)\n",
    "            rho_b += 2*rhot(sub_trace_b, i+1)\n",
    "            \n",
    "        # compute the scaled variance of segment a and b\n",
    "        var_a  = np.var(sub_trace_a)*rho_a/length\n",
    "        var_b  = np.var(sub_trace_b)*rho_b/length\n",
    "        \n",
    "        # compute the z-score of local segment a and b\n",
    "        z[k] = (theta_a-theta_b)/np.sqrt( var_a + var_b)\n",
    "    \n",
    "    return z\n",
    "\n",
    "#if __name__ == \"main\":\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Message Response Times\n",
    "\n",
    "The file `hangout_chat_data.csv` contains the response times of your friend Mark to google hangout chat messages in seconds. Use a method of your choice to read the file into a data frame or a numpy array. Your goal for this problem is to model Mark's chat response time distribution in a Bayesian framework. \n",
    "\n",
    "The description of the data sounds like a Poisson distribution is a good choice for our likelihood. We have messages arriving independently of each other, and instead of the arrival time we consider the time it took Mark to respond to the messages. \n",
    "\n",
    "* Load and describe the data by plotting a histogram of the response times. \n",
    "* Derive and compute the maximum likelihood solution for a Poisson distribution.\n",
    "* Compare this to the Bayesian solution with a prior of your choice and using your own implementation of Metropolis Hastings to sample from the posterior. Make sure to describe why you chose this prior, as well as the specifics of your Metropolis Hastings implementation. \n",
    "\n",
    "* Analyze your sampling using traceplots and convergence tests. You can use the Geweke implementation given above. \n",
    "* Compare your solution to a solution using the MCMC class in pymc and write a brief discussion. Which parameters does your implementation need that the pymc implementation can do without? How do the traceplots compare? \n",
    "\n",
    "* Check your ML solution and the Bayesian solution against the data. If you know how you can use the posterior predictive for the Bayesian solution, otherwise you can use the MAP estimate or the expectation value of the posterior and compare that distribution to the data histogram. \n",
    "\n",
    "* Was our model a good choice for this problem? If yes great, if not, come up with a different Bayesian model that is better capable of capturing the data and show that it works better. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Markov Chains\n",
    "\n",
    "* Given the following transition matrix, examine if the corresponding Markov Chain is irreducible and aperiodic. Note: No formal proof necessary, but you should give a solid argumentation.\n",
    "\n",
    "$$ P = \\left( \n",
    "\\begin{array}{ccccc}\n",
    "0.0 & 0.4 & 0.6 & 0.0 & 0.0 \\\\\n",
    "0.65 & 0.0 & 0.35 & 0.0 & 0.0 \\\\\n",
    "0.32 & 0.68 & 0.0 & 0.0 & 0.0 \\\\\n",
    "0.0 & 0.0 & 0.0 & 0.12 & 0.88 \\\\\n",
    "0.0 & 0.0 & 0.0 & 0.56 & 0.44 \n",
    "\\end{array}\n",
    "\\right ) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Markov Chain is reducible and aperiodic. \n",
    "\n",
    "### Reducible ###\n",
    "By definition, a markov chain is irreducible if the equivalence relation induces only 1 class (p195, Pinsky). This definition means every state must commute any other state. Formally, this is given by $P_{ij}^{(n)} > 0$ for some n. This Markov Chain has 2 equivalent classes. States 1 - 3 commute with each other but cannot transition to states 4-5. So if we start in state 1-3 we can never go into state 4 or 5. The reverse is also true. Hence, this problem has 2 equivalence classes, and hence it is reducible.\n",
    "\n",
    "### Aperiodic ###\n",
    "By definition, a markov chain is aperiodic if every state has period 1 (p198, Pinsky). We also invoke the theorem that states the periodicity of a state within an equivalence class is the same. Hence, we only need to analyze the periodicity of state 1 and 4. \n",
    "\n",
    "State 1 can return to itself in 2 steps (1->2->1)or 3 steps (1->2->3->1) or more. The g.c.d of {2,3...} is 1. Hence, state 1 has a periodicity of 1. Invoking the equivalence theorem state 2 and 3 also have period 1.\n",
    "\n",
    "State 4 and 5 are much simpler. The transition probability among them are non-zeros. It's quiet straightforward to see the period of state 4 and 5 are 1. Consequently, every state has period of 1, so this Markov Chain is aperiodic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: The Evidence \n",
    "\n",
    "In lectures we mostly concentrate on the likelihood and the prior and regard the evidence as a mere normalization factor. However, the evidence can be quite useful. In this problem you will compare different models by computing the evidence for each model, aka the probability that randomly selected parameters from a given model class would generate the data $X$.\n",
    "\n",
    "As our models we compare polynomials of degree 0 to 4. For example for degree 2 we have $y = a_0 + a_1 \\cdot x + a_2 \\cdot x^2 + \\epsilon$ where $\\epsilon \\sim N(0, \\sigma) $ and $\\theta = [a_0, a_1, a_2, \\sigma]$. Assume that for all polynomials $a_i \\sim \\text{Expo}(1)$ and $\\sigma \\sim \\text{Inverse Gamma}(1,1)$.\n",
    "\n",
    "\n",
    "Bayes' theorem states that:\n",
    "$$\n",
    "P(\\theta|x)=\\frac{P(x|\\theta)P(\\theta)}{P(x)}\n",
    "$$\n",
    "$P(\\theta)$ is the prior, $P(x|\\theta)$ is the likelihood, $P(x)$ is called the evidence, and $P(\\theta|x)$ is the posterior.\n",
    "\n",
    "Your tasks are:\n",
    "\n",
    "* Write down the mathematical equation of the evidence in terms of the likelihood and the prior. You don't need to solve the integral analytically, just write down its formula.\n",
    "* Now you have the evidence in the form of an integral. Solve it by using importance sampling. What is a good choice for your importance sampling distribution?\n",
    "* Compare the evidence for polynomials of degree 0 to 4. Which polynomial wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is your data for the problem:\n",
    "data = np.array([[ -1.85519254,  -2.7009541 ],\n",
    "       [  4.38291824,  19.61735369],\n",
    "       [  2.29495208,   3.96481822],\n",
    "       [  0.02075668,   8.00646088],\n",
    "       [  0.54097177,   2.8872262 ]])\n",
    "\n",
    "x=data[:,0]\n",
    "y=data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5: Which YouTube Videos to Watch\n",
    "\n",
    "Youtube videos have a like and an unlike flag. We can use these up and down votes on the videos to determine if a video is worth watching. However, it is not immediately obvious how to rank a video with just 3 up and 0 down rankings against a video with 300 up and 100 down votes. We will address this problem using a Bayesian approach.\n",
    "\n",
    "Build two Bayesian models for the average upvote rate of a video. Both models should use the same likelihood, but different priors. Use one prior where people in general are rather undecided about videos, and one where people tend to be very opinionated. Compare the resulting posteriors for each video. How does the different choice of prior change your results? \n",
    "\n",
    "Given that there are so many videos on YouTube we want a really conservative way to decide if it is worth watching. Compute the 5th percentile for the posterior of each video and rank the videos according to this value. Is the 5th percentile a good indicator for the ranking? What are the benefits, what are potential drawbacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is the [upvote, downvote] data for 4 different videos:\n",
    "video_votes = np.array([[3,0],[300,100],[2,2],[200,100]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
